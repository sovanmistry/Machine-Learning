{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb6e40d1-f826-4b08-a09b-05344c6c5ba0",
   "metadata": {},
   "source": [
    "### 17 Mar Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27aeb853-29a4-4e36-8341-93d76970cd11",
   "metadata": {},
   "source": [
    "Q1: What are missing values in a dataset? Why is it essential to handle missing values? Name some\n",
    "algorithms that are not affected by missing values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5ac9df-20f0-4660-af37-3ded0170e70e",
   "metadata": {},
   "source": [
    "ans: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666f7da2-03b7-4a76-9fd2-a2c44cb69f7f",
   "metadata": {},
   "source": [
    "Missing data, or missing values, occur when you don't have data stored for certain variables or participants. Data can go missing due to incomplete data entry, equipment malfunctions, lost files, and many other reasons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135092ef-e4ae-4e3d-95ff-c9d41d13dcd5",
   "metadata": {},
   "source": [
    "It is important to handle the missing values appropriately.\n",
    "\n",
    "    Many machine learning algorithms fail if the dataset contains missing values. However, algorithms like K-nearest and Naive Bayes support data with missing values.\n",
    "    You may end up building a biased machine learning model, leading to incorrect results if the missing values are not handled properly.\n",
    "    Missing data can lead to a lack of precision in the statistical analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371111de-3234-4de2-85a1-b122046b0999",
   "metadata": {},
   "source": [
    " k-NN and Random Forest algorithms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ce427f-2a7a-4c93-927f-783328b4a862",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3d5328e-0281-4683-a0a5-cec72dc16186",
   "metadata": {},
   "source": [
    "Q2: List down techniques used to handle missing data. Give an example of each with python code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6791f3-82f8-4002-a507-d3e4593f1d0b",
   "metadata": {},
   "source": [
    "ans:\n",
    "\n",
    "Mean value Imputation\n",
    "\n",
    "Median Value Imputation\n",
    "\n",
    "Mode Value Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87ba8957-487f-4498-8a25-a8b62336f37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0ac05d6-bbd3-46fe-819d-a7fc48492a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sns.load_dataset('titanic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7042ef2-e28e-4f7c-9130-8473b8c42016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
       "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
       "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
       "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
       "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
       "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
       "\n",
       "     who  adult_male deck  embark_town alive  alone  \n",
       "0    man        True  NaN  Southampton    no  False  \n",
       "1  woman       False    C    Cherbourg   yes  False  \n",
       "2  woman       False  NaN  Southampton   yes   True  \n",
       "3  woman       False    C  Southampton   yes  False  \n",
       "4    man        True  NaN  Southampton    no   True  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab9ef176-d0ff-4107-a931-5b0e263b17e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    714\n",
       "True     177\n",
       "Name: age, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['age'].isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "750913ab-3a52-4cff-8d38-c11a4aa64c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean Value Imputation\n",
    "df['age_mean'] = df['age'].fillna(df['age'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8dd4575c-6ab4-4a02-a755-193a05613cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Median Value Imputation\n",
    "df['age_median'] = df['age'].fillna(df['age'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "81f1c4c5-d434-4632-968d-05417b06786b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mode Value Imputation\n",
    "mode1 = df['age'].mode()[0]\n",
    "mode1\n",
    "df['age_mode'] = df['age'].fillna(mode1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "80cf4089-48a0-434f-8716-244c90bbdf68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>age_mean</th>\n",
       "      <th>age_median</th>\n",
       "      <th>age_mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>27.0</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>19.0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>NaN</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>28.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>26.0</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>32.0</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age   age_mean  age_median  age_mode\n",
       "0    22.0  22.000000        22.0      22.0\n",
       "1    38.0  38.000000        38.0      38.0\n",
       "2    26.0  26.000000        26.0      26.0\n",
       "3    35.0  35.000000        35.0      35.0\n",
       "4    35.0  35.000000        35.0      35.0\n",
       "..    ...        ...         ...       ...\n",
       "886  27.0  27.000000        27.0      27.0\n",
       "887  19.0  19.000000        19.0      19.0\n",
       "888   NaN  29.699118        28.0      24.0\n",
       "889  26.0  26.000000        26.0      26.0\n",
       "890  32.0  32.000000        32.0      32.0\n",
       "\n",
       "[891 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['age','age_mean','age_median', 'age_mode']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aa56ff7d-4ee8-4d88-ade0-655592b62860",
   "metadata": {},
   "outputs": [],
   "source": [
    "#row 888 has some value \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b750600-7fe9-40eb-8b9c-e84625dfcce7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "270c4ec6-a9ed-46c3-8098-f9ef04c6c962",
   "metadata": {},
   "source": [
    "Q3: Explain the imbalanced data. What will happen if imbalanced data is not handled?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062f9a7a-30c4-450b-8497-c43e09b4fd25",
   "metadata": {},
   "source": [
    "ans:\n",
    "    Imbalanced Data\n",
    "    in this type of datasets target set has uneven distribution of observation\n",
    "    \n",
    "    Model will be biased and behave incorrectly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0628b4f-0f70-4eb6-9677-690e23bceeb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b481195b-d02e-44d1-b302-65c69798b4c3",
   "metadata": {},
   "source": [
    "Q4: What are Up-sampling and Down-sampling? Explain with an example when up-sampling and downsampling\n",
    "are required.\n",
    "\n",
    "ans: \n",
    "    \n",
    "    Upsampling: we can increase the count of minority class as same as count of majority class\n",
    "    Downsampling : we can decrease the count of majority class as same as minority class\n",
    "    \n",
    "up and down sampling is used to get rid of the extra and unnecessary efforts of:\n",
    "\n",
    "    oversampling\n",
    "    reduced order filters\n",
    "    lower sampling rate\n",
    "    realizable filters\n",
    "    faster and easier calculations\n",
    "    interpolating the data\n",
    "    discard useless things\n",
    "    pack-unpack => zip/unzip\n",
    "    \n",
    "example : \n",
    "    to create a compress file(zip) we need downsampling\n",
    "    to expand a zip file we need upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092cd97d-e05d-41ac-ad11-343860de9aba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ca652ae-e8ed-4df5-8357-0a43351f4eeb",
   "metadata": {},
   "source": [
    "Q5: What is data Augmentation? Explain SMOTE.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111027a5-000e-47df-aa24-ebb6f5d94ddb",
   "metadata": {},
   "source": [
    "ans:\n",
    "    \n",
    "    Augmentation : \n",
    "        Data augmentation is a set of techniques to artificially increase the amount of data by generating new data points from existing data.\n",
    "        \n",
    "    SMOTE:\n",
    "        SMOTE is a technique to oversample the minority class .\n",
    "        SMOTE applies K nearest Neighbour algorithm to select random nearest neighbour on Minority class instances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6a82e9-dc04-4867-a1a3-a6beebcfad7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ca43f1e-a22d-4deb-97fb-ccac9a7a6feb",
   "metadata": {},
   "source": [
    "Q6: What are outliers in a dataset? Why is it essential to handle outliers?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04eff8ca-7920-4b4f-bf7d-579159654255",
   "metadata": {},
   "source": [
    "ans:\n",
    "    \n",
    "    Outliers:\n",
    "        Outliers are those data points that are significantly different from the rest of the dataset. They are often abnormal observations that skew the data distribution, and arise due to inconsistent data entry, or erroneous observations\n",
    "        \n",
    "    necessity of Handling Outliers:\n",
    "        As outliers are very different values—abnormally low or abnormally high—their presence can often skew the results of statistical analyses on the dataset. This could lead to less effective and less useful models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798cdc94-bfbd-4f49-89c3-5a3e19458fef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0472059b-1a6d-469e-ba3d-35dc0d0b6aa7",
   "metadata": {},
   "source": [
    "Q7: You are working on a project that requires analyzing customer data. However, you notice that some of\n",
    "the data is missing. What are some techniques you can use to handle the missing data in your analysis?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47f0a86-e30b-4c64-b1c0-54700e597bd7",
   "metadata": {},
   "source": [
    "ans: \n",
    "    we can use several imputation technique\n",
    "    \n",
    "        mean value imputation\n",
    "        median value imputation\n",
    "        mode value imputation\n",
    "        \n",
    "    otherwise we can delete the line items (rows) containing missing data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be96e91-01e6-4cf9-92c5-d58a68f08b74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e901a33f-fd8b-4bd1-bcca-07d95ffba9ef",
   "metadata": {},
   "source": [
    "Q8: You are working with a large dataset and find that a small percentage of the data is missing. What are\n",
    "some strategies you can use to determine if the missing data is missing at random or if there is a pattern\n",
    "to the missing data?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45a5e81-6b27-4234-bc02-c774dc88a745",
   "metadata": {},
   "source": [
    "ans: \n",
    "    \n",
    "    1. find out the the rows which contain missing values\n",
    "    2. try to group those missing values with any column\n",
    "    3. if there is a direct relationship with any columns with our missing data - we can say that missing at random\n",
    "    4. otherwise no pattern found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f10c9a-c6e7-4b4c-8938-4213ea1e4a6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4296deb7-8ddd-4598-94b3-6c1ae08e6cd0",
   "metadata": {},
   "source": [
    "Q9: Suppose you are working on a medical diagnosis project and find that the majority of patients in the\n",
    "dataset do not have the condition of interest, while a small percentage do. What are some strategies you\n",
    "can use to evaluate the performance of your machine learning model on this imbalanced dataset?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01aee057-8ebf-419d-9e49-8766fcd8e07b",
   "metadata": {},
   "source": [
    "ans: \n",
    "    I will follow the Downsampling approach and take those small percentage of patients which has condition of interest.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e450c9db-aa27-4929-8e71-05b536476d53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e494eb71-b046-43fa-ae06-d7c5004cc6c4",
   "metadata": {},
   "source": [
    "Q10: When attempting to estimate customer satisfaction for a project, you discover that the dataset is\n",
    "unbalanced, with the bulk of customers reporting being satisfied. What methods can you employ to\n",
    "balance the dataset and down-sample the majority class?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bbf250-a345-459b-983a-fdffe78ea77f",
   "metadata": {},
   "source": [
    "ans: \n",
    "    \n",
    "    SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2b76e2-087f-4b61-bce9-7c20d5cd6b5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73d9f9b2-f637-40b3-83fe-b10e60596491",
   "metadata": {},
   "source": [
    "Q11: You discover that the dataset is unbalanced with a low percentage of occurrences while working on a\n",
    "project that requires you to estimate the occurrence of a rare event. What methods can you employ to\n",
    "balance the dataset and up-sample the minority class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1343851e-f8c0-463c-81fc-f01e80be66a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans: \n",
    "    we can use SMOTE\n",
    "    also any Interpolation technique works here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
